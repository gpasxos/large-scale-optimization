{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxTDNJEh/YQUYDPWBKXmzD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpasxos/large-scale-optimization/blob/main/ch02_numerical_hessian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a function is twice-differentiable, we can numerically compute its Hessian matrix. The function is convex if and only if:\n",
        "$$ \\nabla^2 f(x) \\succeq 0$$"
      ],
      "metadata": {
        "id": "-LVm-6d5A1FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dQPzEjH_zvw",
        "outputId": "7971ef83-6200-456d-bb0d-7ee6f098aa2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f(x) = x1^2 + 4*x2^2 + 2*x1*x2:\n",
            " Convex: True, Min eigenvalue: 1.3944\n",
            "f(x) = x1^2 - x2^2:\n",
            " Convex: False, Min eigenvalue: -2.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def numerical_hessian(f, x, eps=1e-5):\n",
        "    \"\"\"Compute Hessian of f at x using finite differences.\"\"\"\n",
        "    n = len(x)\n",
        "    H = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            # Second partial derivative via central differences\n",
        "            ei, ej = np.zeros(n), np.zeros(n)\n",
        "            ei[i], ej[j] = eps, eps\n",
        "            H[i, j] = (f(x + ei + ej) - f(x + ei - ej)- f(x - ei + ej) + f(x - ei - ej)) / (4 * eps**2)\n",
        "    return (H + H.T) / 2 # Ensure symmetry\n",
        "\n",
        "def check_convexity_hessian(f, dim=2, n_points=100, bounds=(-5, 5)):\n",
        "    \"\"\"Check if Hessian is PSD at random points.\"\"\"\n",
        "    min_eigenvalue = float('inf')\n",
        "    for _ in range(n_points):\n",
        "        x = np.random.uniform(bounds[0], bounds[1], dim)\n",
        "        H = numerical_hessian(f, x)\n",
        "        eigvals = np.linalg.eigvalsh(H) # Eigenvalues of symmetric matrix\n",
        "        min_eigenvalue = min(min_eigenvalue, eigvals.min())\n",
        "\n",
        "    is_convex = min_eigenvalue >= -1e-8 # Tolerance for numerical error\n",
        "    return is_convex, min_eigenvalue\n",
        "\n",
        "# Test functions\n",
        "def f_convex(x):\n",
        "    return x[0]**2 + 4*x[1]**2 + 2*x[0]*x[1] # Quiz (a)\n",
        "\n",
        "def f_nonconvex(x):\n",
        "    return x[0]**2 - x[1]**2 # Quiz (c)\n",
        "\n",
        "print(\"f(x) = x1^2 + 4*x2^2 + 2*x1*x2:\")\n",
        "is_cvx, min_eig = check_convexity_hessian(f_convex)\n",
        "print(f\" Convex: {is_cvx}, Min eigenvalue: {min_eig:.4f}\")\n",
        "print(\"f(x) = x1^2 - x2^2:\")\n",
        "is_cvx, min_eig = check_convexity_hessian(f_nonconvex)\n",
        "print(f\" Convex: {is_cvx}, Min eigenvalue: {min_eig:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCxZ2Lw9BUiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}