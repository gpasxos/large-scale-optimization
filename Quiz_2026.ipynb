{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUtCsX5LgVNnkAo3l19ggx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpasxos/large-scale-optimization/blob/main/Quiz_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Quiz\n",
        "\n",
        "You are asked to provide a class model that implements an ML model that trains on MNIST and can predict the right logit with high accuracy.\n",
        "\n",
        "**Rules**\n",
        "\n",
        "1. **Imports**: Only `numpy` may be imported\n",
        "2. **No pre-computation**: Training must happen in `fit()` — no hardcoded weights\n",
        "3. **Time limit**: Budget is 120s, hard stop at 180s\n",
        "4. **Accuracy**: Minimum 97% required to pass\n",
        "\n",
        "---\n",
        "\n",
        "## Model Requirements\n",
        "\n",
        "Your model must be a class with two methods:\n",
        "\n",
        "| Method | Input | Output | Purpose |\n",
        "|--------|-------|--------|---------|\n",
        "| `model.fit(X, y)` | `X`: numpy array of shape `(n_samples, 784)` <br> `y`: numpy array of shape `(n_samples,)` | None | Train the interal ML model\n",
        "| `model.predict(X)` | `X`: numpy array of shape `(n_samples, 784)` | numpy array of shape `(n_samples,)` | Output predictions which are used for accuracy evaluations\n",
        "\n",
        "**Data Format**\n",
        "- `X` contains flattened 28×28 grayscale images, normalized to [0, 1]\n",
        "- `y` contains integer labels from 0 to 9\n",
        "\n",
        "---\n",
        "\n",
        "## Example Model Structure\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "class MyModel:\n",
        "    def __init__(self):\n",
        "        # Initialize hyperparameters (NOT pre-trained weights)\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # X: (n_samples, 784) - training images\n",
        "        # y: (n_samples,) - labels 0-9\n",
        "        # Train your model here\n",
        "        pass\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # X: (n_samples, 784) - test images\n",
        "        # Returns: (n_samples,) - predicted labels 0-9\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "-8eHI935DxDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tester Class\n",
        "\n",
        "Below I provide a tester class which serves two purposes: (1) during your development work, it will help you self-evaluate your model and improve it, (2) during assessment, it will be used to evaluate your final submission.\n",
        "\n",
        "**Notice!** The code runs differently for each seed, by breaking the dataset in a unique way per seed. At assessment time, I will use an unknown seed, therefore, you should aim to create a model that generalizes so that it can perform well with any seed."
      ],
      "metadata": {
        "id": "zvolA7-eTuR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usage of tester class**\n",
        "\n",
        "```\n",
        "tester = MNISTTester()\n",
        "results = tester.test(your_model, seed=42, min_accuracy=0.85)\n",
        "```"
      ],
      "metadata": {
        "id": "LYBulfZ-D8B9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "31e6IT1B0SRA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "class MNISTTester:\n",
        "    \"\"\"\n",
        "    MNIST Model Tester\n",
        "    - Students develop with seed=42\n",
        "    - Teacher grades with a different seed\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._X = None\n",
        "        self._y = None\n",
        "\n",
        "    def _load_data(self):\n",
        "        if self._X is None:\n",
        "            print(\"Loading MNIST...\")\n",
        "            mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
        "            self._X = mnist.data / 255.0\n",
        "            self._y = mnist.target.astype(int)\n",
        "        return self._X, self._y\n",
        "\n",
        "    def test(self, model, seed=42, min_accuracy=0.80, subset=None, max_time=500):\n",
        "        \"\"\"\n",
        "        Test a model on MNIST.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        model : object with fit(X, y) and predict(X) methods\n",
        "        seed : int - controls train/test split\n",
        "        min_accuracy : float - minimum accuracy to pass\n",
        "        subset : int or None - use smaller dataset for faster testing\n",
        "        max_time : float - maximum allowed time in seconds (default 5 min)\n",
        "        \"\"\"\n",
        "        X, y = self._load_data()\n",
        "\n",
        "        # Optional subset for faster iteration\n",
        "        if subset:\n",
        "            np.random.seed(seed)\n",
        "            idx = np.random.choice(len(X), subset, replace=False)\n",
        "            X, y = X[idx], y[idx]\n",
        "\n",
        "        # Split data based on seed\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.15, random_state=seed, stratify=y\n",
        "        )\n",
        "\n",
        "        print(f\"Seed: {seed} | Train: {len(X_train)} | Test: {len(X_test)} | Time limit: {max_time}s\")\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        # Train\n",
        "        model.fit(X_train, y_train)\n",
        "        train_time = time.time() - start\n",
        "\n",
        "        if train_time > max_time:\n",
        "            print(f\"FAILED: Training took {train_time:.1f}s (limit: {max_time}s)\")\n",
        "            return {'accuracy': 0, 'passed': False, 'time': train_time, 'seed': seed}\n",
        "\n",
        "        # Predict\n",
        "        y_pred = np.array(model.predict(X_test)).flatten()\n",
        "        total_time = time.time() - start\n",
        "\n",
        "        if total_time > max_time:\n",
        "            print(f\"FAILED: Total time {total_time:.1f}s exceeded limit {max_time}s\")\n",
        "            return {'accuracy': 0, 'passed': False, 'time': total_time, 'seed': seed}\n",
        "\n",
        "        # Evaluate\n",
        "        accuracy = np.mean(y_pred == y_test)\n",
        "        passed = accuracy >= min_accuracy and total_time <= max_time\n",
        "\n",
        "        print(f\"Accuracy: {accuracy*100:.2f}% | Time: {total_time:.1f}s | {'PASSED' if passed else 'FAILED'}\")\n",
        "\n",
        "        return {'accuracy': accuracy, 'passed': passed, 'time': total_time, 'seed': seed}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a simple submission\n",
        "\n",
        "Here we provide an example of what the student should deliver. **Important:** The submission consists of a single block of code that can be pasted in this jupyter file.\n",
        "\n",
        "This particular example builds a simple softmax regression with low performance, but the idea is to explain how your code should look like.\n",
        "\n",
        "Make sure your code runs in no more than 2min and with accuracy at least 97%. To get top grade, try to beat 98.5%. When you will submit your code, I will simply copy-paste your code in the space below and execute it. Above, I will have chosen a different seed."
      ],
      "metadata": {
        "id": "WxA29hS71mNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class SoftmaxRegression:\n",
        "    \"\"\"\n",
        "    Multi-class logistic regression using gradient descent.\n",
        "    Simple linear model: no hidden layers, just input -> output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=0.1, n_iterations=100):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.W = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_classes = 10\n",
        "\n",
        "        # Initialize weights\n",
        "        self.W = np.zeros((n_features, n_classes))\n",
        "        self.b = np.zeros(n_classes)\n",
        "\n",
        "        # One-hot encode labels\n",
        "        y_onehot = np.zeros((n_samples, n_classes))\n",
        "        y_onehot[np.arange(n_samples), y] = 1\n",
        "\n",
        "        # Gradient descent\n",
        "        for i in range(self.n_iterations):\n",
        "            # Forward pass\n",
        "            scores = X @ self.W + self.b\n",
        "            probs = self._softmax(scores)\n",
        "\n",
        "            # Gradients\n",
        "            error = probs - y_onehot\n",
        "            grad_W = (X.T @ error) / n_samples\n",
        "            grad_b = np.mean(error, axis=0)\n",
        "\n",
        "            # Update weights\n",
        "            self.W -= self.lr * grad_W\n",
        "            self.b -= self.lr * grad_b\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = X @ self.W + self.b\n",
        "        return np.argmax(scores, axis=1)\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "tester = MNISTTester()\n",
        "model = SoftmaxRegression(learning_rate=0.1, n_iterations=200)\n",
        "results = tester.test(model, seed=42, min_accuracy=0.85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWRxWZ6R5uBx",
        "outputId": "8feb89d0-00d3-4b25-b865-fa5a1c6680b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MNIST...\n",
            "Seed: 42 | Train: 59500 | Test: 10500 | Time limit: 300s\n",
            "Accuracy: 87.83% | Time: 75.3s | PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to create a model that generalizes, because the evaluation will happen with a seed that is unknown to you, which impacts the train-test process as shown below."
      ],
      "metadata": {
        "id": "5KN7QIrp9kwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a small example: 20 samples\n",
        "data_indices = np.arange(20)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"How different seeds create different train/test splits\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nSample indices: 0-19\")\n",
        "print(\"█ = Train, ░ = Test\\n\")\n",
        "\n",
        "for seed in [42, 123, 2024, 7]:\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        data_indices, test_size=0.3, random_state=seed\n",
        "    )\n",
        "\n",
        "    # Create visual representation\n",
        "    visual = \"\"\n",
        "    for i in range(20):\n",
        "        if i in train_idx:\n",
        "            visual += \"█\"\n",
        "        else:\n",
        "            visual += \"░\"\n",
        "\n",
        "    print(f\"Seed {seed:4d}: {visual}  (Train: {sorted(test_idx)})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Same seed = Same split (reproducible)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "for seed in [42, 42, 42]:\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        data_indices, test_size=0.3, random_state=seed\n",
        "    )\n",
        "    visual = \"\".join([\"█\" if i in train_idx else \"░\" for i in range(20)])\n",
        "    print(f\"Seed {seed:4d}: {visual}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpNQLW86VpU",
        "outputId": "087332ea-3d48-4a77-9e0e-8cc662c54a26"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "How different seeds create different train/test splits\n",
            "============================================================\n",
            "\n",
            "Sample indices: 0-19\n",
            "█ = Train, ░ = Test\n",
            "\n",
            "Seed   42: ░░███░██░██████░█░██  (Train: [np.int64(0), np.int64(1), np.int64(5), np.int64(8), np.int64(15), np.int64(17)])\n",
            "Seed  123: ████░░█░░█████░██░██  (Train: [np.int64(4), np.int64(5), np.int64(7), np.int64(8), np.int64(14), np.int64(17)])\n",
            "Seed 2024: ██████░████░░░█░███░  (Train: [np.int64(6), np.int64(11), np.int64(12), np.int64(13), np.int64(15), np.int64(19)])\n",
            "Seed    7: ░░░██░█████░█████░██  (Train: [np.int64(0), np.int64(1), np.int64(2), np.int64(5), np.int64(11), np.int64(17)])\n",
            "\n",
            "============================================================\n",
            "Same seed = Same split (reproducible)\n",
            "============================================================\n",
            "\n",
            "Seed   42: ░░███░██░██████░█░██\n",
            "Seed   42: ░░███░██░██████░█░██\n",
            "Seed   42: ░░███░██░██████░█░██\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kV2jATu6E89z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}